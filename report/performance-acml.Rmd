---
title: "Performace of ACML"
author: "Shawn Garbett"
date: "May 22, 2018"
output: html_document
---

<style type="text/css">
.failure {background-color: pink;}

body, td {
   font-size: 12px;
}
code.r{
  font-size: 12px;
}
pre {
  font-size: 10px
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tangram)
library(Hmisc)
library(purrr)
```

```{r functions, include=FALSE, cache=TRUE}
source("../setup.R")
scenarios <- inits.sim

# Helper function for repeated operation over files.
load.results <- function(target="../output", verbose=FALSE)
{
  files <- paste0(target, "/", dir(target))
  
  do.call(rbind, lapply(files, function(f) {
    if(verbose) cat("Loading ", f, "\n")
    load(f)
    
    results
  }))
}
results <- load.results(verbose=TRUE)

n <- length(unique(results$Scenario))

results <- cleanup.import(
  results,
  labels= c("Job", "Scenario", "Sampling", "Method", 
            rep(c("Intercept", "Time", "Group", "Confounder", "Interaction"), times=4)
            )
)

results$Sampling <- factor(results$Sampling,
                           levels=c("Random", "Intercept", "Mix1", "Mix2", "Slope"))

```

## Purpose

In preparing for a CRAN packaging and improvements of the ODS4LDA (Outcome Dependent Sampling for Longitudinal Data Analysis) code is is desirable to understand the statistical performance of the proposed estimators. As such, this document examines the bias, precision, coverage and accuracy of the library for a variety of cases.

The code being tested is available in the git commit hash `3d69d4925188ff9eeb2ea7568473f7db6c46ecc1`.

### Method
`r N` individuals were simulated using `r length(prev.grp)` mixed effect models,

```
hn_scale=c(1.5, 2, 0.5, 0.1)
```

```{r, results='asis'}
for(i in 1:length(prev.grp))
{
  cat("### Model Run",i,"\n\n")
  parm <- inits.sim[i,]
  cat("$$y_{ij} = ",parm[1], parm[2]," t_{ij} ",parm[3]," g_i ",parm[4]," c_i ",parm[5]," t_{ij} g_i  + b_{0i} + b_{1i} t_{ij} + \\epsilon_{ij}$$\n", sep='')
  cat("$$\\begin{bmatrix} b_{0i} \\\\ b_{1i} \\\\ \\end{bmatrix} \\sim \\mathcal{N}\\left(\\begin{bmatrix} 0\\\\0\\\\ \\end{bmatrix},\\begin{bmatrix} ", exp(parm[6])^2,"& 0 \\\\ 0 & ", round(exp(parm[7])^2,4), " \\\\ \\end{bmatrix} \\right)$$\n")
  cat("$$ \\epsilon_{ij} \\sim \\mathcal{N}(0, ", round(exp(parm[9])^2,4), ")$$")
  cat("\n\n")
}

```



where $t_{ij}$ represents the $j$th timepoint for the $i$th individual, $g_i$ is the presence or absence of a SNIP or expensive binomial information for the $i$th individual, $c_i$ is the presence or absence of a confounder for the $i$th individual. Membership in the $g_i$ group occurs at a 0.3 probability.

This was used to create between 4 to 6 observations at equally spaced time points for each individual.

During each of the 2000 runs approximately 400 individuals were sampled using a Bernoulli strategy for stratum. 

From these runs, we examine the 95\% coverage intervals, the observed bias of estimation and compare the variance of the estimates to the average of the variances estimated by the model using both methods on the same subsampled data sets, as well as examine the accuracy and precision.

The fitting is done by a variety of different methods. Each of the combinations of 4 sampling methods: random, intercept, slope and mixture1 and mixture2 crossed with fitting methods: ACML, weighted likelihood, direct multiple imputation (`r n.imp` replicates) and Two Phase exluding one duplicate method for random sampling (wl).

## Results

### Bias


```{r, results='asis', echo=FALSE}

cell_func <- function(table, row, column, fun=NULL, ...)
{
  colname <- NULL
  try({colname <- derive_label(column)}, silent=TRUE)
  if(is.null(colname)) try({colname <- derive_label(column$left)}, silent=TRUE)
  if(is.null(colname)) colname <- column$string()
  table <- col_header(table, colname)
  major <- unique(row$left$data)
  minor <- levels(row$right$data)

  for(m in major)
  {
    first <- m
    for(n in minor)
    {
      table <- row_header(table, list(first, n), sub=FALSE)
      first <- ""
      table <- add_row(table, fun(column, m == row$left$data & n == row$right$data))
    }
  }
  
  table
}

est.bias      <- function(column, selector)
{
  data  <- column$data[selector]
  test  <- t.test(data, na.rm=TRUE)
  cls   <- if(test$p.value < 0.001) "failure" else NULL
  ci    <- paste0(render_f(test$estimate, 3), 
                  " (", render_f(test$conf.int[1], 3), ", ",
                  render_f(test$conf.int[2], 3), ")")
  cell(ci, class=cls)
}

bias_table <- function(m)
{
  html5(tangram(diff.int + diff.time + diff.grp + diff.conf + diff.tg ~ Scenario*Sampling,
         data=subset(results, Method==m), transforms = cell_func, fun=est.bias, id=paste0(m, "_bias"),
        caption=paste(m, "Estimator Bias"), style="nejm",
         footnote="Values in Pink have p < 0.001"))
}

all_bias_table <- function()
{
   all <- paste0(sapply(c("ACML", "MI", "TwoPhase"), function(m) bias_table(m)), collapse='<br/>')
   class(all) <- c("html", "character")
   all
}

all_bias_table()

```
<br/>

```{r, , results='asis', echo=FALSE}
var.bias <- function(column, selector)
{
  truth    <- var(column$left$data[selector])   # variance of estimates
  estimate <- mean(column$right$data[selector]) # mean of estimated variances

  percent  <- 100*(estimate-truth)/truth
  cls      <- if(is.na(percent) || abs(percent) > 10) "failure" else NULL
  f_per    <- if(is.na(percent)) "-" else render_f(percent, 1)
  cell(f_per, class=cls)
}

var.bias_table <- function(m)
{
  html5(tangram(est.int * var.int    +
                   est.time* var.time + 
                   est.grp * var.grp  +
                   est.conf* var.conf +
                   est.tg  * var.tg   ~ Scenario*Sampling,
           data=subset(results, Method==m),
           transforms = cell_func, fun=var.bias,
           id=paste0(m, "_varbias"),
           caption=paste(m, "Variance Bias Relative Percent"),
           style="nejm",
           footnote="Values in Pink have exceed 10%"))
}

all_var.bias_table <- function()
{
   all <- paste0(sapply(c("ACML", "MI", "TwoPhase"), function(m) var.bias_table(m)), collapse='<br/>')
   class(all) <- c("html", "character")
   all
}

all_var.bias_table()
```

### Coverage

```{r, results='asis', echo=FALSE}
coverage <- function(table,
                     row,
                     column,
                     ...)
{
  grid          <- table(as.categorical(row$data), as.categorical(column$data), useNA="no")
  validcol      <- which(!apply(grid,2,FUN = function(x){all(x == 0)}))
  validrow      <- which(!apply(grid,1,FUN = function(x){all(x == 0)}))
  ncol          <- dim(grid)[2]
  nrow          <- dim(grid)[1]
  

  denominators  <- matrix(rep(colSums(grid), nrow), ncol=ncol, byrow=TRUE)
  rowlabels     <- rownames(grid)

  # Compute overall N values for each category
  # length(datac[datac == cat & !is.na(datac)])
  subN <- lapply(colnames(grid), FUN=function(cat)
    cell_n( sum(column$data == cat, na.rm=TRUE), subcol=cat)
  )

  # Why is this so difficult?

  # More complex name derivation
  name <- row$name()
  try({
        l2 <- attr(row$data, "label")
        if(!is.null(l2)) {name<-l2}
  })

  # Select part of grid table, then do all the munging to get it back in form
  x <- matrix(grid[2,], nrow=1)
  colnames(x) <- colnames(grid)
  rownames(x) <- name
  grid <- x
  denominators <- matrix(denominators[2,], nrow=1)
  nrow <- 1

  # Column Headers
  table <- col_header(table, colnames(grid))
  table <- col_header(table, subN)

    # Row Headers
  if(nrow > 1) table <- row_header(table, derive_label(row)) # Deal with single
  for(nm in rownames(grid)) table <- row_header(table, nm)

  # Now loop the grid into the table as a fraction
  for(j in 1:ncol)
  {
    if(nrow > 1) table <- add_row(table, "")
    for(i in 1:nrow)
    {
      table <-
        if(denominators[i,j] == 0)
          add_row(table, "")
        else
        {
          test <- suppressWarnings(prop.test(grid[i,j], denominators[i,j], p=0.95))
          
          cls <- if(test$p.value < 0.001) "failure" else NULL
          add_row(table, cell(paste0(
            render_f(test$estimate*100, 1), " (",
            render_f(test$conf.int[1]*100, 1), ", ",
            render_f(test$conf.int[2]*100, 1), ")"
          ), class=cls))
        }
    }
    table <- new_col(table)
  }

  table
}

cover_table <- function(sample, subbatch)
{
  html5(tangram(
           Method ~ cover.int+cover.time+cover.grp+cover.conf+cover.tg,
           subset(results, Sampling==sample & Scenario == subbatch),
           transforms=coverage,
           id=paste0(sample,"_",subbatch),
           caption=paste(sample, "Sampling Coverage Scenario", subbatch),
           style="nejm", footnote="Values in Pink have p < 0.001"))
}

all_cover_table <- function()
{
   all <- paste0(sapply(c("Random", "Intercept", "Slope", "Mix1", "Mix2"), function(m) {
     paste0(sapply(1:n, function(x) cover_table(m, x)), collapse='<br/>')
   }), collapse='<br/>')
   class(all) <- c("html", "character")
   all
}

all_cover_table()
```

### Efficiency

```{r efficiency, echo=FALSE}

ref <- subset(results, Sampling=="Random" & Method=="ACML")

efficiency <- function(table, column, row, ref, scenario, ...)
{
  ran        <- mean(ref[,row$right$string()]) # Comparison
  
  datac      <- as.categorical(column$data)
  categories <- levels(datac)

  table <- col_header(table, derive_label(row$right))
  table <- row_header(table, scenario)
  table <- add_row(table, "")
  for(i in categories)
  {
    table <- row_header(table, paste0("  ", i))

    result <- paste0(
      sapply(unique(row$left$data), function(method) {
       selector <- datac==i & (row$left$data == method)
       render_f(ran/mean(row$right$data[selector]),2)
       }),
      collapse=", ")

    table <- add_row(table, paste0("(",result,")") )
  }
  
  table
}

eff.inner <- function(m, sc)
{
  tangram(Method*(var.int+var.time+var.grp+var.conf+var.tg) ~ Sampling,
          data=subset(results, Method %in% m  & Scenario==sc),
          ref =subset(ref,     Method=="ACML" & Scenario==sc),
          scenario=sc,
          transforms=efficiency, id="tmp")
}
eff <- function(m)
{
  tbl <- purrr::reduce(lapply(1:length(prev.grp), function(i) eff.inner(m, i)), rbind)
    
  attr(tbl, "caption") <- paste0("Efficiency (", paste0(m, collapse=", "), ")")
  attr(tbl, "style")   <- "nejm"

  tbl
}

```

```{r eff_acml, results='asis', echo=FALSE}
html5(eff(c("ACML", "MI", "TwoPhase")))
```



Thus concludes this round of simulation.

